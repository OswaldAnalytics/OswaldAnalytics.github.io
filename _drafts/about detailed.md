---
layout: page
title: About
---

**Studies**
I am a graduate student at UNC: Chapel Hill studying quantitative methods in educational research and self-regulated learning.  The focus of my research is on variable selection for self-regulated learning data that is generated with a think aloud protocol methodology as learners work through a learning task.  Since self-regulated learning in this method is regarded as an event, often there are many variables that are associated with learning outcomes.  My research examines ways to reduce these variables into useful subsets.  

My past research was into examining how students perceived their interactions with video games and examining what aspects of video games experiences produce aggressive responses.  Other research I have done is examining retention in MOOCs and examining the relationship of locus of control and sensation seeking on academic achievement.  

The big picture of my studies is to understand how learners interact with digital learning environments, whether they are MOOCs, hypermedia or video games.  I try to find out what motivates learnerâ€™s actions within the environment, and what skills learners use on average and how are they related to learning outcomes.  Ideally patterns of design aspects can be identified as predictive of motivated learning and embedded scaffolding and inform design to encourage learner actions related to high learning outcomes.  For instance, if students are naturally motivated by cooperative elements in a learning environment, then introducing a way for learners to interact cooperatively may increase learning by the students.  Likewise, if students who compare different viewpoints presented in a learning environment are shown on average to have higher learning outcomes, then a feature can be added to the learning environment to encourage this behavior.

**Interests**
My main interests in education and psychology outside of interactive learning environments and learning games are methods of inquiry and evaluation.  The best research is planned research, and to this extent I study research methodology.  The method I use currently and have found the most useful is think aloud protocols methodology.  In this method students complete a task while thinking aloud.  Then, their verbalizations are transcribed and coded using qualitative style analysis methods.  If no prior research has been done, the coding is open and is the transcripts are analyzed with grounded theory.  If prior research has been done, ideally a book of codes has been produced that is used for coding.  The codes can then be analyzed with quantitative methods with the coded events treated as counts of occurrence.  To use this method, I trained both in qualitative methodology and quantitative methodology.

I also have been interested in how studies measure the outcomes variables they use.  For example, in the research on video games and aggression, almost no two studies use the same statistical method to determine an aggressive outcome, despite using the same method to measure aggression.  In learning studies, the learning outcome measure is often heavily left skewed with many learning achieving maximum scores, which makes analysis slightly harder any variation between the learners that would occur above the cap is lost.  To this end I want to examine how outcomes differ if one makes a test like an educational test were most people pass, to a test where outcomes become distributed normally.

Finally, I have been examining using a predictive learning framework to reexamine some of the studies that I have worked on.  With machine learning becoming more and more assessable, and speed of computers increasing, new options to analyze data are emerging that deal with different problems of traditional regression based analysis, such as non-linearity or multicollinearity.  Also with the increase in discussion of bayesian methods I have been slowly trying to learn how these methods can help me answer different research questions.

**Data Skills**
Data is not always presented in the manner that is best suited for analysis.  To this end I have been learning different programs and languages to better work with data.  I do not want my analyses to be limited by form I receive data in.  While routine tasks I use SPSS (the common program my research colleagues use), I also use R for any personal work with Python as needed.  I have worked with SAS and MPLUS but not as much as I would like. 

Beyond data analysis, I also work on learning data science.  Generally, my data comes in clean form from SPSS databases, but once working with data Coursera showed me the need to learn a lot more about working with data across formats.  The data we received was in a SQL dump format, and having this simply rendered into flat tables held up the study I was working on seven weeks as no one was familiar with SQL.  To this end I been working with Python, with some Unix and R, to clean up data.  Joining data sets and using regx to extract data of interest greatly increases the type of data I can work with.  Beautiful Soup allows me to write scripts to take the data I want from various websites, then convert it into a usable format.  While this can be done by hand, when there are dozens are pages each with one piece of data I want, this added step can save a lot of time in the end.

**Areas I Wish to Learn More About**
I currently am hoping to find a mentor for machine learning and Bayesian statistics.  While both are understandable with texts and videos, I find a few areas still confusing enough to know I need guidance at some point.  There seems to be a disconnect in how these methods work mathematically and how they should best be explained practically, without resorting to explaining them as a black box.  While some authors can easily accomplish this, this is an area I struggle with.  For traditional statistics, I have a basic training in simple longitudinal methods and SEM modeling, but would like to expand this out and learn more, practically growth curve models.  Multi-level models are an area my skills are lacking in, so I seek to expand my knowledge here as well.

Incorporating more programming based ideas into my research is another area I am actively seeking to learn.  In particular, version control, automation and reproducibility are areas of interest.  Version control uses things like Git to track changes to a file, very useful for tracking edits to publication drafts or changes to analyses.  Automation I seek to use to eliminate as much data entry as possible.  Ideally, a process should be created to take data from different parts of an experiment, such as score totals, survey results, counts of occurrences, and create a dataset without having students copy the information manually.  Manually copying information from even a sheet of paper to a database leads to some degree of measurement error.  Finally, I am actively using reproducible research tactics with my studies, in particular saving the exact scripts I use to transform, clean and analyze data.  Learning the syntax of SPSS is very useful here, as while I can present the results of analyses in a format my colleagues are familiar with, I can also save the syntax script to create a log of actions that was performed.  

Finally, tying much of this together, I am trying to learn to analyze data following a think aloud protocol as a pattern of events.  Currently the methodology I use reduces these to counts of incidences that occur over the task.  But this method lacks the ability to detect patterns of codes that occur.  Examining data as dyads or triad of codes is something I actively exploring.  Research into this area is something I am unqiuely qualified for as my interests in qualitative methods, quantatitive methods and programming I believe would allow me to take the qualitative data, code it, then create dyads and triads of codes using computer programming that can be examined with machine learning methods to determine if they are predictive of learning outcomes.